{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b3b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = pd.read_csv(\"all_viruses_v2.csv\")\n",
    "df = resample(\n",
    "    df,\n",
    "    replace=False,\n",
    "    n_samples=5000,  # Adjust the desired size accordingly\n",
    "    random_state=42\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf03592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_PepID</th>\n",
       "      <th>Info_organism_id</th>\n",
       "      <th>Info_protein_id</th>\n",
       "      <th>Info_pos</th>\n",
       "      <th>Info_AA</th>\n",
       "      <th>Info_pubmed_id</th>\n",
       "      <th>Info_epitope_id</th>\n",
       "      <th>Info_host_id</th>\n",
       "      <th>Info_nPos</th>\n",
       "      <th>Info_nNeg</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1802191G:4</td>\n",
       "      <td>11060</td>\n",
       "      <td>1802191G</td>\n",
       "      <td>322</td>\n",
       "      <td>R</td>\n",
       "      <td>25758647</td>\n",
       "      <td>101410</td>\n",
       "      <td>9606</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253440</td>\n",
       "      <td>-0.054703</td>\n",
       "      <td>-0.107563</td>\n",
       "      <td>0.134034</td>\n",
       "      <td>-0.637219</td>\n",
       "      <td>-0.162080</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>-0.088826</td>\n",
       "      <td>0.086144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVV62528.1:2</td>\n",
       "      <td>1335626</td>\n",
       "      <td>AVV62528.1</td>\n",
       "      <td>23</td>\n",
       "      <td>V</td>\n",
       "      <td>33580175</td>\n",
       "      <td>1414002,1445067,1447054,1447189,1453217,146430...</td>\n",
       "      <td>9606</td>\n",
       "      <td>2,0,0,0,0,1,0,1,0,1,1,0</td>\n",
       "      <td>4,3,3,3,3,2,3,5,3,2,5,3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134029</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>-0.034534</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>-1.427791</td>\n",
       "      <td>-0.373679</td>\n",
       "      <td>0.342157</td>\n",
       "      <td>0.108768</td>\n",
       "      <td>0.022009</td>\n",
       "      <td>0.438011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P04664.1:2</td>\n",
       "      <td>387147</td>\n",
       "      <td>P04664.1</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>7907197</td>\n",
       "      <td>43396</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054698</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>0.059747</td>\n",
       "      <td>-1.410822</td>\n",
       "      <td>-0.148060</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>0.325288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVV62532.1:3</td>\n",
       "      <td>1335626</td>\n",
       "      <td>AVV62532.1</td>\n",
       "      <td>70</td>\n",
       "      <td>P</td>\n",
       "      <td>33580175</td>\n",
       "      <td>1415087,1431596,1450532</td>\n",
       "      <td>9606</td>\n",
       "      <td>1,1,0</td>\n",
       "      <td>5,2,3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>-0.006412</td>\n",
       "      <td>-0.013110</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>-0.376308</td>\n",
       "      <td>-0.116565</td>\n",
       "      <td>-0.045770</td>\n",
       "      <td>0.169865</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.164597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q32ZE1.1:139</td>\n",
       "      <td>64320</td>\n",
       "      <td>Q32ZE1.1</td>\n",
       "      <td>2363</td>\n",
       "      <td>M</td>\n",
       "      <td>34290707</td>\n",
       "      <td>1639820,1642282</td>\n",
       "      <td>9606</td>\n",
       "      <td>2,1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162415</td>\n",
       "      <td>-0.131412</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>-0.114282</td>\n",
       "      <td>-1.066111</td>\n",
       "      <td>-0.270772</td>\n",
       "      <td>-0.216460</td>\n",
       "      <td>-0.042336</td>\n",
       "      <td>-0.143749</td>\n",
       "      <td>0.030633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>QLJ58334.1:3</td>\n",
       "      <td>11089</td>\n",
       "      <td>QLJ58334.1</td>\n",
       "      <td>33</td>\n",
       "      <td>Q</td>\n",
       "      <td>34290707</td>\n",
       "      <td>1640521,1640535</td>\n",
       "      <td>9606</td>\n",
       "      <td>1,3</td>\n",
       "      <td>1,0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029241</td>\n",
       "      <td>0.104362</td>\n",
       "      <td>-0.015846</td>\n",
       "      <td>0.046372</td>\n",
       "      <td>-1.725452</td>\n",
       "      <td>0.105030</td>\n",
       "      <td>-0.059988</td>\n",
       "      <td>0.133097</td>\n",
       "      <td>-0.058139</td>\n",
       "      <td>0.178787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>NP_828857.1:1</td>\n",
       "      <td>227984</td>\n",
       "      <td>NP_828857.1</td>\n",
       "      <td>103</td>\n",
       "      <td>L</td>\n",
       "      <td>34143766</td>\n",
       "      <td>1667951,1691068,1687547,1653847,1655781,170544...</td>\n",
       "      <td>9606</td>\n",
       "      <td>2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>0,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033840</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>-0.584922</td>\n",
       "      <td>-0.052751</td>\n",
       "      <td>0.107107</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>-0.113937</td>\n",
       "      <td>-0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>AAP55696.1:2</td>\n",
       "      <td>31650</td>\n",
       "      <td>AAP55696.1</td>\n",
       "      <td>341</td>\n",
       "      <td>P</td>\n",
       "      <td>10092013</td>\n",
       "      <td>40036</td>\n",
       "      <td>9606</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067478</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>-0.117948</td>\n",
       "      <td>-0.071127</td>\n",
       "      <td>-0.655211</td>\n",
       "      <td>-0.021679</td>\n",
       "      <td>0.102668</td>\n",
       "      <td>0.045259</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.173507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>CAA25008.1:12</td>\n",
       "      <td>11824</td>\n",
       "      <td>CAA25008.1</td>\n",
       "      <td>455</td>\n",
       "      <td>T</td>\n",
       "      <td>1689371</td>\n",
       "      <td>78895</td>\n",
       "      <td>9986</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664487</td>\n",
       "      <td>-0.247076</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>-0.065329</td>\n",
       "      <td>-0.078010</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.099166</td>\n",
       "      <td>-0.102281</td>\n",
       "      <td>0.074428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>P03306.2:4</td>\n",
       "      <td>12112</td>\n",
       "      <td>P03306.2</td>\n",
       "      <td>873</td>\n",
       "      <td>S</td>\n",
       "      <td>2578661,2434606,6190676</td>\n",
       "      <td>19023,9106,9107,60801</td>\n",
       "      <td>9986,10000000,10141</td>\n",
       "      <td>7,4,2,2,4</td>\n",
       "      <td>1,1,1,0,0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137678</td>\n",
       "      <td>-0.024112</td>\n",
       "      <td>0.182430</td>\n",
       "      <td>-0.057860</td>\n",
       "      <td>-0.738719</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>-0.055247</td>\n",
       "      <td>-0.007010</td>\n",
       "      <td>-0.069705</td>\n",
       "      <td>0.329940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Info_PepID  Info_organism_id Info_protein_id  Info_pos Info_AA  \\\n",
       "0        1802191G:4             11060        1802191G       322       R   \n",
       "1      AVV62528.1:2           1335626      AVV62528.1        23       V   \n",
       "2        P04664.1:2            387147        P04664.1        63       N   \n",
       "3      AVV62532.1:3           1335626      AVV62532.1        70       P   \n",
       "4      Q32ZE1.1:139             64320        Q32ZE1.1      2363       M   \n",
       "...             ...               ...             ...       ...     ...   \n",
       "4995   QLJ58334.1:3             11089      QLJ58334.1        33       Q   \n",
       "4996  NP_828857.1:1            227984     NP_828857.1       103       L   \n",
       "4997   AAP55696.1:2             31650      AAP55696.1       341       P   \n",
       "4998  CAA25008.1:12             11824      CAA25008.1       455       T   \n",
       "4999     P03306.2:4             12112        P03306.2       873       S   \n",
       "\n",
       "               Info_pubmed_id  \\\n",
       "0                    25758647   \n",
       "1                    33580175   \n",
       "2                     7907197   \n",
       "3                    33580175   \n",
       "4                    34290707   \n",
       "...                       ...   \n",
       "4995                 34290707   \n",
       "4996                 34143766   \n",
       "4997                 10092013   \n",
       "4998                  1689371   \n",
       "4999  2578661,2434606,6190676   \n",
       "\n",
       "                                        Info_epitope_id         Info_host_id  \\\n",
       "0                                                101410                 9606   \n",
       "1     1414002,1445067,1447054,1447189,1453217,146430...                 9606   \n",
       "2                                                 43396             10000000   \n",
       "3                               1415087,1431596,1450532                 9606   \n",
       "4                                       1639820,1642282                 9606   \n",
       "...                                                 ...                  ...   \n",
       "4995                                    1640521,1640535                 9606   \n",
       "4996  1667951,1691068,1687547,1653847,1655781,170544...                 9606   \n",
       "4997                                              40036                 9606   \n",
       "4998                                              78895                 9986   \n",
       "4999                              19023,9106,9107,60801  9986,10000000,10141   \n",
       "\n",
       "                            Info_nPos                        Info_nNeg  ...  \\\n",
       "0                                   2                                0  ...   \n",
       "1             2,0,0,0,0,1,0,1,0,1,1,0          4,3,3,3,3,2,3,5,3,2,5,3  ...   \n",
       "2                                   1                                0  ...   \n",
       "3                               1,1,0                            5,2,3  ...   \n",
       "4                                 2,1                              0,1  ...   \n",
       "...                               ...                              ...  ...   \n",
       "4995                              1,3                              1,0  ...   \n",
       "4996  2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0  0,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2  ...   \n",
       "4997                                0                                5  ...   \n",
       "4998                                3                                0  ...   \n",
       "4999                        7,4,2,2,4                        1,1,1,0,0  ...   \n",
       "\n",
       "     feat_esm1b_1270 feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "0           0.253440       -0.054703        -0.107563         0.134034   \n",
       "1          -0.134029        0.170800        -0.034534        -0.014796   \n",
       "2           0.054698        0.050047         0.032328         0.059747   \n",
       "3           0.006032       -0.006412        -0.013110         0.078516   \n",
       "4           0.162415       -0.131412         0.002491        -0.114282   \n",
       "...              ...             ...              ...              ...   \n",
       "4995        0.029241        0.104362        -0.015846         0.046372   \n",
       "4996       -0.033840       -0.012273         0.024326         0.106536   \n",
       "4997        0.067478       -0.188705        -0.117948        -0.071127   \n",
       "4998        0.664487       -0.247076        -0.005394         0.044484   \n",
       "4999        0.137678       -0.024112         0.182430        -0.057860   \n",
       "\n",
       "      feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "0           -0.637219        -0.162080         0.019305         0.007423   \n",
       "1           -1.427791        -0.373679         0.342157         0.108768   \n",
       "2           -1.410822        -0.148060         0.006109         0.037935   \n",
       "3           -0.376308        -0.116565        -0.045770         0.169865   \n",
       "4           -1.066111        -0.270772        -0.216460        -0.042336   \n",
       "...               ...              ...              ...              ...   \n",
       "4995        -1.725452         0.105030        -0.059988         0.133097   \n",
       "4996        -0.584922        -0.052751         0.107107         0.011512   \n",
       "4997        -0.655211        -0.021679         0.102668         0.045259   \n",
       "4998        -0.065329        -0.078010         0.110370         0.099166   \n",
       "4999        -0.738719         0.019618        -0.055247        -0.007010   \n",
       "\n",
       "      feat_esm1b_1278  feat_esm1b_1279  \n",
       "0           -0.088826         0.086144  \n",
       "1            0.022009         0.438011  \n",
       "2           -0.033530         0.325288  \n",
       "3            0.015900         0.164597  \n",
       "4           -0.143749         0.030633  \n",
       "...               ...              ...  \n",
       "4995        -0.058139         0.178787  \n",
       "4996        -0.113937        -0.004184  \n",
       "4997         0.008659         0.173507  \n",
       "4998        -0.102281         0.074428  \n",
       "4999        -0.069705         0.329940  \n",
       "\n",
       "[5000 rows x 1294 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b369c7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd19ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column:\n",
      "feat_esm1b_633    56\n",
      "feat_esm1b_876    56\n",
      "feat_esm1b_854    56\n",
      "feat_esm1b_853    56\n",
      "feat_esm1b_852    56\n",
      "                  ..\n",
      "feat_esm1b_422    56\n",
      "feat_esm1b_421    56\n",
      "feat_esm1b_420    56\n",
      "feat_esm1b_419    56\n",
      "feat_esm1b_418    56\n",
      "Length: 1280, dtype: int64\n",
      "there are missing values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_missing_values(dataframe):\n",
    "    # Count the number of missing values in each column\n",
    "    missing_values = dataframe.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    # Filter out columns with no missing values\n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "    # Print the table of missing values in descending order\n",
    "    print(\"Number of missing values in each column:\")\n",
    "    print(missing_values)\n",
    "\n",
    "    # Plot a bar graph of missing values (only for columns with missing values)\n",
    "    if not missing_values.empty:\n",
    "        print(\"there are missing values\")\n",
    "    else:\n",
    "        print(\"No columns with missing values.\")\n",
    "\n",
    "\n",
    "print_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60579de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d72acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Info_cluster  Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
      "0                8      1      0.179011      0.203662      0.024505   \n",
      "1              589     -1      0.150422     -0.013744      0.000510   \n",
      "2                1      1      0.278986      0.172278     -0.123253   \n",
      "3              575     -1      0.041575      0.164590     -0.117662   \n",
      "4                8     -1      0.384218     -0.133514      0.114821   \n",
      "...            ...    ...           ...           ...           ...   \n",
      "4995             8     -1     -0.177775      0.244810     -0.086172   \n",
      "4996           566     -1     -0.038724      0.123018      0.256502   \n",
      "4997            28     -1     -0.002630     -0.109005      0.431068   \n",
      "4998           216      1      0.414099      0.584960      0.029198   \n",
      "4999            42      1     -0.067634      0.202856      0.140018   \n",
      "\n",
      "      feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  \\\n",
      "0        -0.010472      0.174965     -0.043751     -0.046647     -0.073059   \n",
      "1        -0.196507     -0.060163     -0.159714     -0.273806     -0.360895   \n",
      "2        -0.124267     -0.315093     -0.067858      0.084728      0.010211   \n",
      "3         0.135435      0.126703     -0.260181      0.207925      0.128663   \n",
      "4        -0.188002      0.122835     -0.369093     -0.004826      0.037529   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "4995      0.255502      0.026809     -0.288194     -0.095950      0.338768   \n",
      "4996      0.226812      0.243118      0.029011     -0.100194      0.123279   \n",
      "4997     -0.218709      0.009205     -0.389868      0.124127      0.045773   \n",
      "4998      0.127751      0.042172     -0.438991     -0.318802      0.100138   \n",
      "4999      0.106829      0.012735     -0.244443     -0.012073     -0.062521   \n",
      "\n",
      "      ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
      "0     ...         0.253440        -0.054703        -0.107563         0.134034   \n",
      "1     ...        -0.134029         0.170800        -0.034534        -0.014796   \n",
      "2     ...         0.054698         0.050047         0.032328         0.059747   \n",
      "3     ...         0.006032        -0.006412        -0.013110         0.078516   \n",
      "4     ...         0.162415        -0.131412         0.002491        -0.114282   \n",
      "...   ...              ...              ...              ...              ...   \n",
      "4995  ...         0.029241         0.104362        -0.015846         0.046372   \n",
      "4996  ...        -0.033840        -0.012273         0.024326         0.106536   \n",
      "4997  ...         0.067478        -0.188705        -0.117948        -0.071127   \n",
      "4998  ...         0.664487        -0.247076        -0.005394         0.044484   \n",
      "4999  ...         0.137678        -0.024112         0.182430        -0.057860   \n",
      "\n",
      "      feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
      "0           -0.637219        -0.162080         0.019305         0.007423   \n",
      "1           -1.427791        -0.373679         0.342157         0.108768   \n",
      "2           -1.410822        -0.148060         0.006109         0.037935   \n",
      "3           -0.376308        -0.116565        -0.045770         0.169865   \n",
      "4           -1.066111        -0.270772        -0.216460        -0.042336   \n",
      "...               ...              ...              ...              ...   \n",
      "4995        -1.725452         0.105030        -0.059988         0.133097   \n",
      "4996        -0.584922        -0.052751         0.107107         0.011512   \n",
      "4997        -0.655211        -0.021679         0.102668         0.045259   \n",
      "4998        -0.065329        -0.078010         0.110370         0.099166   \n",
      "4999        -0.738719         0.019618        -0.055247        -0.007010   \n",
      "\n",
      "      feat_esm1b_1278  feat_esm1b_1279  \n",
      "0           -0.088826         0.086144  \n",
      "1            0.022009         0.438011  \n",
      "2           -0.033530         0.325288  \n",
      "3            0.015900         0.164597  \n",
      "4           -0.143749         0.030633  \n",
      "...               ...              ...  \n",
      "4995        -0.058139         0.178787  \n",
      "4996        -0.113937        -0.004184  \n",
      "4997         0.008659         0.173507  \n",
      "4998        -0.102281         0.074428  \n",
      "4999        -0.069705         0.329940  \n",
      "\n",
      "[4944 rows x 1282 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop columns starting with \"Info_\" except \"Info_cluster\"\n",
    "columns_to_drop = df.filter(regex='^Info_(?!cluster)').columns\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d33470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types are consistent across the dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_datatype_consistent(dataframe):\n",
    "    consistent = True\n",
    "    for col in dataframe.columns:\n",
    "        unique_dtypes = dataframe[col].apply(lambda x: type(x)).nunique()\n",
    "        if unique_dtypes > 1:\n",
    "            print(f\"Inconsistent data types found in column '{col}'.\")\n",
    "            consistent = False\n",
    "    if consistent:\n",
    "        print(\"Data types are consistent across the dataset.\")\n",
    "    return consistent\n",
    "\n",
    "is_datatype_consistent(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e30a6",
   "metadata": {},
   "source": [
    "Standardizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc49ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Create a mask to identify non-class columns\n",
    "mask = df.columns != \"Class\"\n",
    "\n",
    "df.loc[:, mask] = scaler.fit_transform(df.loc[:, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c5e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"Class\")\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb04b2f",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2cc3cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1281\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t115\n",
      "Tentative: \t226\n",
      "Rejected: \t940\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t115\n",
      "Tentative: \t226\n",
      "Rejected: \t940\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t115\n",
      "Tentative: \t226\n",
      "Rejected: \t940\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t115\n",
      "Tentative: \t226\n",
      "Rejected: \t940\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t120\n",
      "Tentative: \t155\n",
      "Rejected: \t1006\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t120\n",
      "Tentative: \t155\n",
      "Rejected: \t1006\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t120\n",
      "Tentative: \t155\n",
      "Rejected: \t1006\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t120\n",
      "Tentative: \t155\n",
      "Rejected: \t1006\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t124\n",
      "Tentative: \t130\n",
      "Rejected: \t1027\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t124\n",
      "Tentative: \t130\n",
      "Rejected: \t1027\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t124\n",
      "Tentative: \t130\n",
      "Rejected: \t1027\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t113\n",
      "Rejected: \t1042\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t113\n",
      "Rejected: \t1042\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t113\n",
      "Rejected: \t1042\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t99\n",
      "Rejected: \t1054\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t99\n",
      "Rejected: \t1054\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t99\n",
      "Rejected: \t1054\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t99\n",
      "Rejected: \t1054\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t99\n",
      "Rejected: \t1054\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t94\n",
      "Rejected: \t1059\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t128\n",
      "Tentative: \t94\n",
      "Rejected: \t1059\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t84\n",
      "Rejected: \t1067\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t84\n",
      "Rejected: \t1067\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t84\n",
      "Rejected: \t1067\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t75\n",
      "Rejected: \t1076\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t75\n",
      "Rejected: \t1076\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t75\n",
      "Rejected: \t1076\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t69\n",
      "Rejected: \t1082\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t130\n",
      "Tentative: \t69\n",
      "Rejected: \t1082\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t68\n",
      "Rejected: \t1082\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t68\n",
      "Rejected: \t1082\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t66\n",
      "Rejected: \t1084\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t61\n",
      "Rejected: \t1089\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t61\n",
      "Rejected: \t1089\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t61\n",
      "Rejected: \t1089\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t61\n",
      "Rejected: \t1089\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t61\n",
      "Rejected: \t1089\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t131\n",
      "Tentative: \t59\n",
      "Rejected: \t1091\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t58\n",
      "Rejected: \t1091\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t56\n",
      "Rejected: \t1093\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t56\n",
      "Rejected: \t1093\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t51\n",
      "Rejected: \t1098\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t51\n",
      "Rejected: \t1098\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t51\n",
      "Rejected: \t1098\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t50\n",
      "Rejected: \t1099\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t50\n",
      "Rejected: \t1099\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t46\n",
      "Rejected: \t1103\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t46\n",
      "Rejected: \t1103\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t132\n",
      "Tentative: \t46\n",
      "Rejected: \t1103\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t133\n",
      "Tentative: \t45\n",
      "Rejected: \t1103\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t133\n",
      "Tentative: \t45\n",
      "Rejected: \t1103\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t42\n",
      "Rejected: \t1105\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t42\n",
      "Rejected: \t1105\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t42\n",
      "Rejected: \t1105\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t42\n",
      "Rejected: \t1105\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t41\n",
      "Rejected: \t1106\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t41\n",
      "Rejected: \t1106\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t40\n",
      "Rejected: \t1107\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t40\n",
      "Rejected: \t1107\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t40\n",
      "Rejected: \t1107\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t39\n",
      "Rejected: \t1108\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t38\n",
      "Rejected: \t1109\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t38\n",
      "Rejected: \t1109\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t38\n",
      "Rejected: \t1109\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t38\n",
      "Rejected: \t1109\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t38\n",
      "Rejected: \t1109\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t37\n",
      "Rejected: \t1110\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t35\n",
      "Rejected: \t1112\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t34\n",
      "Rejected: \t1113\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t34\n",
      "Rejected: \t1113\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t34\n",
      "Rejected: \t1113\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t34\n",
      "Rejected: \t1113\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t34\n",
      "Rejected: \t1113\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t134\n",
      "Tentative: \t0\n",
      "Rejected: \t1113\n",
      "Selected Features:\n",
      "['Info_cluster', 'feat_esm1b_15', 'feat_esm1b_38', 'feat_esm1b_46', 'feat_esm1b_69', 'feat_esm1b_70', 'feat_esm1b_76', 'feat_esm1b_87', 'feat_esm1b_89', 'feat_esm1b_125', 'feat_esm1b_128', 'feat_esm1b_141', 'feat_esm1b_162', 'feat_esm1b_179', 'feat_esm1b_188', 'feat_esm1b_197', 'feat_esm1b_213', 'feat_esm1b_217', 'feat_esm1b_224', 'feat_esm1b_252', 'feat_esm1b_254', 'feat_esm1b_255', 'feat_esm1b_265', 'feat_esm1b_267', 'feat_esm1b_279', 'feat_esm1b_290', 'feat_esm1b_302', 'feat_esm1b_303', 'feat_esm1b_304', 'feat_esm1b_308', 'feat_esm1b_313', 'feat_esm1b_324', 'feat_esm1b_330', 'feat_esm1b_331', 'feat_esm1b_343', 'feat_esm1b_344', 'feat_esm1b_358', 'feat_esm1b_367', 'feat_esm1b_392', 'feat_esm1b_397', 'feat_esm1b_413', 'feat_esm1b_423', 'feat_esm1b_434', 'feat_esm1b_447', 'feat_esm1b_450', 'feat_esm1b_455', 'feat_esm1b_457', 'feat_esm1b_459', 'feat_esm1b_472', 'feat_esm1b_474', 'feat_esm1b_476', 'feat_esm1b_484', 'feat_esm1b_487', 'feat_esm1b_494', 'feat_esm1b_500', 'feat_esm1b_509', 'feat_esm1b_526', 'feat_esm1b_535', 'feat_esm1b_541', 'feat_esm1b_564', 'feat_esm1b_570', 'feat_esm1b_600', 'feat_esm1b_621', 'feat_esm1b_628', 'feat_esm1b_639', 'feat_esm1b_643', 'feat_esm1b_646', 'feat_esm1b_659', 'feat_esm1b_665', 'feat_esm1b_668', 'feat_esm1b_669', 'feat_esm1b_670', 'feat_esm1b_671', 'feat_esm1b_679', 'feat_esm1b_684', 'feat_esm1b_699', 'feat_esm1b_711', 'feat_esm1b_725', 'feat_esm1b_728', 'feat_esm1b_733', 'feat_esm1b_741', 'feat_esm1b_757', 'feat_esm1b_771', 'feat_esm1b_777', 'feat_esm1b_785', 'feat_esm1b_789', 'feat_esm1b_795', 'feat_esm1b_801', 'feat_esm1b_805', 'feat_esm1b_810', 'feat_esm1b_847', 'feat_esm1b_854', 'feat_esm1b_874', 'feat_esm1b_877', 'feat_esm1b_882', 'feat_esm1b_884', 'feat_esm1b_898', 'feat_esm1b_904', 'feat_esm1b_909', 'feat_esm1b_927', 'feat_esm1b_928', 'feat_esm1b_929', 'feat_esm1b_933', 'feat_esm1b_936', 'feat_esm1b_942', 'feat_esm1b_960', 'feat_esm1b_966', 'feat_esm1b_1015', 'feat_esm1b_1043', 'feat_esm1b_1050', 'feat_esm1b_1056', 'feat_esm1b_1103', 'feat_esm1b_1109', 'feat_esm1b_1110', 'feat_esm1b_1125', 'feat_esm1b_1132', 'feat_esm1b_1148', 'feat_esm1b_1153', 'feat_esm1b_1156', 'feat_esm1b_1159', 'feat_esm1b_1166', 'feat_esm1b_1167', 'feat_esm1b_1180', 'feat_esm1b_1183', 'feat_esm1b_1186', 'feat_esm1b_1208', 'feat_esm1b_1216', 'feat_esm1b_1223', 'feat_esm1b_1231', 'feat_esm1b_1233', 'feat_esm1b_1237', 'feat_esm1b_1239', 'feat_esm1b_1240', 'feat_esm1b_1274']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Convert X and y to numpy arrays\n",
    "X_array = X.values\n",
    "y_array = y.values\n",
    "\n",
    "# Initialize a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Initialize Boruta feature selection\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2)\n",
    "\n",
    "# Perform feature selection\n",
    "boruta_selector.fit(X_array, y_array)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[boruta_selector.support_].to_list()\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc8352f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Info_cluster',\n",
       " 'feat_esm1b_15',\n",
       " 'feat_esm1b_38',\n",
       " 'feat_esm1b_46',\n",
       " 'feat_esm1b_69',\n",
       " 'feat_esm1b_70',\n",
       " 'feat_esm1b_76',\n",
       " 'feat_esm1b_87',\n",
       " 'feat_esm1b_89',\n",
       " 'feat_esm1b_125',\n",
       " 'feat_esm1b_128',\n",
       " 'feat_esm1b_141',\n",
       " 'feat_esm1b_162',\n",
       " 'feat_esm1b_179',\n",
       " 'feat_esm1b_188',\n",
       " 'feat_esm1b_197',\n",
       " 'feat_esm1b_213',\n",
       " 'feat_esm1b_217',\n",
       " 'feat_esm1b_224',\n",
       " 'feat_esm1b_252',\n",
       " 'feat_esm1b_254',\n",
       " 'feat_esm1b_255',\n",
       " 'feat_esm1b_265',\n",
       " 'feat_esm1b_267',\n",
       " 'feat_esm1b_279',\n",
       " 'feat_esm1b_290',\n",
       " 'feat_esm1b_302',\n",
       " 'feat_esm1b_303',\n",
       " 'feat_esm1b_304',\n",
       " 'feat_esm1b_308',\n",
       " 'feat_esm1b_313',\n",
       " 'feat_esm1b_324',\n",
       " 'feat_esm1b_330',\n",
       " 'feat_esm1b_331',\n",
       " 'feat_esm1b_343',\n",
       " 'feat_esm1b_344',\n",
       " 'feat_esm1b_358',\n",
       " 'feat_esm1b_367',\n",
       " 'feat_esm1b_392',\n",
       " 'feat_esm1b_397',\n",
       " 'feat_esm1b_413',\n",
       " 'feat_esm1b_423',\n",
       " 'feat_esm1b_434',\n",
       " 'feat_esm1b_447',\n",
       " 'feat_esm1b_450',\n",
       " 'feat_esm1b_455',\n",
       " 'feat_esm1b_457',\n",
       " 'feat_esm1b_459',\n",
       " 'feat_esm1b_472',\n",
       " 'feat_esm1b_474',\n",
       " 'feat_esm1b_476',\n",
       " 'feat_esm1b_484',\n",
       " 'feat_esm1b_487',\n",
       " 'feat_esm1b_494',\n",
       " 'feat_esm1b_500',\n",
       " 'feat_esm1b_509',\n",
       " 'feat_esm1b_526',\n",
       " 'feat_esm1b_535',\n",
       " 'feat_esm1b_541',\n",
       " 'feat_esm1b_564',\n",
       " 'feat_esm1b_570',\n",
       " 'feat_esm1b_600',\n",
       " 'feat_esm1b_621',\n",
       " 'feat_esm1b_628',\n",
       " 'feat_esm1b_639',\n",
       " 'feat_esm1b_643',\n",
       " 'feat_esm1b_646',\n",
       " 'feat_esm1b_659',\n",
       " 'feat_esm1b_665',\n",
       " 'feat_esm1b_668',\n",
       " 'feat_esm1b_669',\n",
       " 'feat_esm1b_670',\n",
       " 'feat_esm1b_671',\n",
       " 'feat_esm1b_679',\n",
       " 'feat_esm1b_684',\n",
       " 'feat_esm1b_699',\n",
       " 'feat_esm1b_711',\n",
       " 'feat_esm1b_725',\n",
       " 'feat_esm1b_728',\n",
       " 'feat_esm1b_733',\n",
       " 'feat_esm1b_741',\n",
       " 'feat_esm1b_757',\n",
       " 'feat_esm1b_771',\n",
       " 'feat_esm1b_777',\n",
       " 'feat_esm1b_785',\n",
       " 'feat_esm1b_789',\n",
       " 'feat_esm1b_795',\n",
       " 'feat_esm1b_801',\n",
       " 'feat_esm1b_805',\n",
       " 'feat_esm1b_810',\n",
       " 'feat_esm1b_847',\n",
       " 'feat_esm1b_854',\n",
       " 'feat_esm1b_874',\n",
       " 'feat_esm1b_877',\n",
       " 'feat_esm1b_882',\n",
       " 'feat_esm1b_884',\n",
       " 'feat_esm1b_898',\n",
       " 'feat_esm1b_904',\n",
       " 'feat_esm1b_909',\n",
       " 'feat_esm1b_927',\n",
       " 'feat_esm1b_928',\n",
       " 'feat_esm1b_929',\n",
       " 'feat_esm1b_933',\n",
       " 'feat_esm1b_936',\n",
       " 'feat_esm1b_942',\n",
       " 'feat_esm1b_960',\n",
       " 'feat_esm1b_966',\n",
       " 'feat_esm1b_1015',\n",
       " 'feat_esm1b_1043',\n",
       " 'feat_esm1b_1050',\n",
       " 'feat_esm1b_1056',\n",
       " 'feat_esm1b_1103',\n",
       " 'feat_esm1b_1109',\n",
       " 'feat_esm1b_1110',\n",
       " 'feat_esm1b_1125',\n",
       " 'feat_esm1b_1132',\n",
       " 'feat_esm1b_1148',\n",
       " 'feat_esm1b_1153',\n",
       " 'feat_esm1b_1156',\n",
       " 'feat_esm1b_1159',\n",
       " 'feat_esm1b_1166',\n",
       " 'feat_esm1b_1167',\n",
       " 'feat_esm1b_1180',\n",
       " 'feat_esm1b_1183',\n",
       " 'feat_esm1b_1186',\n",
       " 'feat_esm1b_1208',\n",
       " 'feat_esm1b_1216',\n",
       " 'feat_esm1b_1223',\n",
       " 'feat_esm1b_1231',\n",
       " 'feat_esm1b_1233',\n",
       " 'feat_esm1b_1237',\n",
       " 'feat_esm1b_1239',\n",
       " 'feat_esm1b_1240',\n",
       " 'feat_esm1b_1274',\n",
       " 'Class']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features.append(\"Class\")\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb85d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 3708\n",
      "Testing data size: 1236\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing dataset (50%)\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Printing the sizes of each split\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"Testing data size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa3967",
   "metadata": {},
   "source": [
    "Import lentivirus dataset and split data into training, testing, and hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce452b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lentivirus = pd.read_csv(\"lentivirus_data.csv\")\n",
    "lentivirus = lentivirus[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfda08a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_cluster</th>\n",
       "      <th>feat_esm1b_15</th>\n",
       "      <th>feat_esm1b_38</th>\n",
       "      <th>feat_esm1b_46</th>\n",
       "      <th>feat_esm1b_69</th>\n",
       "      <th>feat_esm1b_70</th>\n",
       "      <th>feat_esm1b_76</th>\n",
       "      <th>feat_esm1b_87</th>\n",
       "      <th>feat_esm1b_89</th>\n",
       "      <th>feat_esm1b_125</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1208</th>\n",
       "      <th>feat_esm1b_1216</th>\n",
       "      <th>feat_esm1b_1223</th>\n",
       "      <th>feat_esm1b_1231</th>\n",
       "      <th>feat_esm1b_1233</th>\n",
       "      <th>feat_esm1b_1237</th>\n",
       "      <th>feat_esm1b_1239</th>\n",
       "      <th>feat_esm1b_1240</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.540395</td>\n",
       "      <td>-0.216428</td>\n",
       "      <td>-0.302226</td>\n",
       "      <td>-1.438174</td>\n",
       "      <td>-0.698117</td>\n",
       "      <td>-0.570326</td>\n",
       "      <td>-0.004256</td>\n",
       "      <td>1.738732</td>\n",
       "      <td>1.228630</td>\n",
       "      <td>0.143393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681933</td>\n",
       "      <td>-1.452177</td>\n",
       "      <td>0.895137</td>\n",
       "      <td>-0.499066</td>\n",
       "      <td>0.692009</td>\n",
       "      <td>-0.030795</td>\n",
       "      <td>0.250912</td>\n",
       "      <td>-0.965501</td>\n",
       "      <td>-0.055663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.134951</td>\n",
       "      <td>-0.285615</td>\n",
       "      <td>1.767132</td>\n",
       "      <td>-1.477632</td>\n",
       "      <td>0.858826</td>\n",
       "      <td>-0.641164</td>\n",
       "      <td>-0.031943</td>\n",
       "      <td>0.141120</td>\n",
       "      <td>-0.067709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.899429</td>\n",
       "      <td>-0.640552</td>\n",
       "      <td>1.878700</td>\n",
       "      <td>-1.881437</td>\n",
       "      <td>1.903750</td>\n",
       "      <td>2.271861</td>\n",
       "      <td>-0.760145</td>\n",
       "      <td>-0.303356</td>\n",
       "      <td>-1.140141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.249803</td>\n",
       "      <td>0.406335</td>\n",
       "      <td>-0.738025</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>-0.066081</td>\n",
       "      <td>1.611213</td>\n",
       "      <td>0.390279</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.603131</td>\n",
       "      <td>0.650429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774447</td>\n",
       "      <td>0.447515</td>\n",
       "      <td>0.547603</td>\n",
       "      <td>-0.071099</td>\n",
       "      <td>0.290806</td>\n",
       "      <td>0.385756</td>\n",
       "      <td>-0.394139</td>\n",
       "      <td>-0.811954</td>\n",
       "      <td>-1.022798</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.540395</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>1.089837</td>\n",
       "      <td>-1.259625</td>\n",
       "      <td>-0.266833</td>\n",
       "      <td>1.028665</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>1.021837</td>\n",
       "      <td>-0.814386</td>\n",
       "      <td>-0.683253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642049</td>\n",
       "      <td>-0.690860</td>\n",
       "      <td>0.928036</td>\n",
       "      <td>-1.243663</td>\n",
       "      <td>-0.076666</td>\n",
       "      <td>1.470194</td>\n",
       "      <td>-0.549170</td>\n",
       "      <td>0.291507</td>\n",
       "      <td>1.226694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237438</td>\n",
       "      <td>0.489113</td>\n",
       "      <td>-0.064441</td>\n",
       "      <td>1.825180</td>\n",
       "      <td>-0.649976</td>\n",
       "      <td>0.463370</td>\n",
       "      <td>-0.444029</td>\n",
       "      <td>-0.113687</td>\n",
       "      <td>0.279925</td>\n",
       "      <td>0.305693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>-0.196377</td>\n",
       "      <td>1.951778</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>-0.521479</td>\n",
       "      <td>0.230404</td>\n",
       "      <td>-0.813507</td>\n",
       "      <td>-0.276400</td>\n",
       "      <td>-0.212514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.456892</td>\n",
       "      <td>-0.093494</td>\n",
       "      <td>-0.758069</td>\n",
       "      <td>0.645052</td>\n",
       "      <td>-0.495986</td>\n",
       "      <td>0.997834</td>\n",
       "      <td>-0.174821</td>\n",
       "      <td>-0.386930</td>\n",
       "      <td>1.063937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257233</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>0.618666</td>\n",
       "      <td>-0.631028</td>\n",
       "      <td>-0.062281</td>\n",
       "      <td>0.217803</td>\n",
       "      <td>-0.061111</td>\n",
       "      <td>-1.324875</td>\n",
       "      <td>-0.127970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1.249803</td>\n",
       "      <td>1.246963</td>\n",
       "      <td>0.219468</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>-0.251273</td>\n",
       "      <td>1.682956</td>\n",
       "      <td>0.272542</td>\n",
       "      <td>-1.015553</td>\n",
       "      <td>-0.205831</td>\n",
       "      <td>0.945232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966267</td>\n",
       "      <td>-1.124424</td>\n",
       "      <td>-0.039834</td>\n",
       "      <td>0.898539</td>\n",
       "      <td>0.501087</td>\n",
       "      <td>1.055738</td>\n",
       "      <td>-0.048068</td>\n",
       "      <td>-0.652693</td>\n",
       "      <td>-0.811461</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>-0.540395</td>\n",
       "      <td>0.290393</td>\n",
       "      <td>1.111766</td>\n",
       "      <td>-0.360445</td>\n",
       "      <td>0.907644</td>\n",
       "      <td>1.123556</td>\n",
       "      <td>-0.632260</td>\n",
       "      <td>0.458548</td>\n",
       "      <td>0.578723</td>\n",
       "      <td>-0.077712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291996</td>\n",
       "      <td>0.748973</td>\n",
       "      <td>-0.117876</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>0.231927</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.655237</td>\n",
       "      <td>0.094564</td>\n",
       "      <td>-0.254380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2.489171</td>\n",
       "      <td>1.131738</td>\n",
       "      <td>0.668270</td>\n",
       "      <td>1.844005</td>\n",
       "      <td>-0.232214</td>\n",
       "      <td>1.297577</td>\n",
       "      <td>-2.172808</td>\n",
       "      <td>0.705767</td>\n",
       "      <td>-0.347523</td>\n",
       "      <td>0.677735</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042847</td>\n",
       "      <td>-1.196159</td>\n",
       "      <td>-1.710789</td>\n",
       "      <td>-0.719528</td>\n",
       "      <td>-0.988258</td>\n",
       "      <td>-0.337754</td>\n",
       "      <td>-1.790046</td>\n",
       "      <td>0.242890</td>\n",
       "      <td>-0.691822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.417774</td>\n",
       "      <td>-0.876880</td>\n",
       "      <td>-0.444512</td>\n",
       "      <td>0.733776</td>\n",
       "      <td>0.718691</td>\n",
       "      <td>0.501822</td>\n",
       "      <td>-0.129049</td>\n",
       "      <td>0.106511</td>\n",
       "      <td>0.411048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208193</td>\n",
       "      <td>0.217460</td>\n",
       "      <td>0.476187</td>\n",
       "      <td>0.136675</td>\n",
       "      <td>-0.769659</td>\n",
       "      <td>0.270891</td>\n",
       "      <td>-1.390005</td>\n",
       "      <td>-0.885951</td>\n",
       "      <td>-0.434397</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Info_cluster  feat_esm1b_15  feat_esm1b_38  feat_esm1b_46  \\\n",
       "0        -0.540395      -0.216428      -0.302226      -1.438174   \n",
       "1        -0.237438      -0.134951      -0.285615       1.767132   \n",
       "2         1.249803       0.406335      -0.738025       0.617204   \n",
       "3        -0.540395       0.992717       1.089837      -1.259625   \n",
       "4        -0.237438       0.489113      -0.064441       1.825180   \n",
       "...            ...            ...            ...            ...   \n",
       "1004     -0.237438      -0.456892      -0.093494      -0.758069   \n",
       "1005      1.249803       1.246963       0.219468       0.010194   \n",
       "1006     -0.540395       0.290393       1.111766      -0.360445   \n",
       "1007      2.489171       1.131738       0.668270       1.844005   \n",
       "1008     -0.237438      -0.417774      -0.876880      -0.444512   \n",
       "\n",
       "      feat_esm1b_69  feat_esm1b_70  feat_esm1b_76  feat_esm1b_87  \\\n",
       "0         -0.698117      -0.570326      -0.004256       1.738732   \n",
       "1         -1.477632       0.858826      -0.641164      -0.031943   \n",
       "2         -0.066081       1.611213       0.390279       0.009539   \n",
       "3         -0.266833       1.028665       0.964597       1.021837   \n",
       "4         -0.649976       0.463370      -0.444029      -0.113687   \n",
       "...             ...            ...            ...            ...   \n",
       "1004       0.645052      -0.495986       0.997834      -0.174821   \n",
       "1005      -0.251273       1.682956       0.272542      -1.015553   \n",
       "1006       0.907644       1.123556      -0.632260       0.458548   \n",
       "1007      -0.232214       1.297577      -2.172808       0.705767   \n",
       "1008       0.733776       0.718691       0.501822      -0.129049   \n",
       "\n",
       "      feat_esm1b_89  feat_esm1b_125  ...  feat_esm1b_1208  feat_esm1b_1216  \\\n",
       "0          1.228630        0.143393  ...        -0.681933        -1.452177   \n",
       "1          0.141120       -0.067709  ...        -0.899429        -0.640552   \n",
       "2          0.603131        0.650429  ...        -0.774447         0.447515   \n",
       "3         -0.814386       -0.683253  ...         0.642049        -0.690860   \n",
       "4          0.279925        0.305693  ...         0.295531        -0.196377   \n",
       "...             ...             ...  ...              ...              ...   \n",
       "1004      -0.386930        1.063937  ...         0.257233        -0.007098   \n",
       "1005      -0.205831        0.945232  ...        -0.966267        -1.124424   \n",
       "1006       0.578723       -0.077712  ...         0.291996         0.748973   \n",
       "1007      -0.347523        0.677735  ...         1.042847        -1.196159   \n",
       "1008       0.106511        0.411048  ...        -0.208193         0.217460   \n",
       "\n",
       "      feat_esm1b_1223  feat_esm1b_1231  feat_esm1b_1233  feat_esm1b_1237  \\\n",
       "0            0.895137        -0.499066         0.692009        -0.030795   \n",
       "1            1.878700        -1.881437         1.903750         2.271861   \n",
       "2            0.547603        -0.071099         0.290806         0.385756   \n",
       "3            0.928036        -1.243663        -0.076666         1.470194   \n",
       "4            1.951778         0.059358        -0.521479         0.230404   \n",
       "...               ...              ...              ...              ...   \n",
       "1004         0.618666        -0.631028        -0.062281         0.217803   \n",
       "1005        -0.039834         0.898539         0.501087         1.055738   \n",
       "1006        -0.117876         0.329348         0.231927         0.003698   \n",
       "1007        -1.710789        -0.719528        -0.988258        -0.337754   \n",
       "1008         0.476187         0.136675        -0.769659         0.270891   \n",
       "\n",
       "      feat_esm1b_1239  feat_esm1b_1240  feat_esm1b_1274  Class  \n",
       "0            0.250912        -0.965501        -0.055663      1  \n",
       "1           -0.760145        -0.303356        -1.140141      1  \n",
       "2           -0.394139        -0.811954        -1.022798     -1  \n",
       "3           -0.549170         0.291507         1.226694      1  \n",
       "4           -0.813507        -0.276400        -0.212514      1  \n",
       "...               ...              ...              ...    ...  \n",
       "1004        -0.061111        -1.324875        -0.127970      1  \n",
       "1005        -0.048068        -0.652693        -0.811461     -1  \n",
       "1006         0.655237         0.094564        -0.254380      1  \n",
       "1007        -1.790046         0.242890        -0.691822      1  \n",
       "1008        -1.390005        -0.885951        -0.434397     -1  \n",
       "\n",
       "[1009 rows x 135 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lentivirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c88ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = lentivirus.columns != \"Class\"\n",
    "lentivirus.loc[:, mask] = scaler.fit_transform(lentivirus.loc[:, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7cce95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Info_cluster  feat_esm1b_15  feat_esm1b_38  feat_esm1b_46  \\\n",
      "0        -0.545448      -0.230647      -0.286184      -1.485622   \n",
      "1        -0.236353      -0.147458      -0.269390       1.806092   \n",
      "2         1.281020       0.405205      -0.726787       0.625164   \n",
      "3        -0.545448       1.003910       1.121221      -1.302260   \n",
      "4        -0.236353       0.489723      -0.045779       1.865705   \n",
      "...            ...            ...            ...            ...   \n",
      "1004     -0.236353      -0.476164      -0.075152      -0.787184   \n",
      "1005      1.281020       1.263499       0.241259       0.001790   \n",
      "1006     -0.545448       0.286826       1.143392      -0.378840   \n",
      "1007      2.545498       1.145853       0.695008       1.885037   \n",
      "1008     -0.236353      -0.436224      -0.867172      -0.465174   \n",
      "\n",
      "      feat_esm1b_69  feat_esm1b_70  feat_esm1b_76  feat_esm1b_87  \\\n",
      "0         -0.725927      -0.587752       0.012327       1.752067   \n",
      "1         -1.503250       0.848221      -0.622604      -0.015455   \n",
      "2         -0.095668       1.604199       0.405638       0.025953   \n",
      "3         -0.295856       1.018870       0.978173       1.036449   \n",
      "4         -0.677921       0.450878      -0.426081      -0.097053   \n",
      "...             ...            ...            ...            ...   \n",
      "1004       0.613465      -0.513057       1.011306      -0.158079   \n",
      "1005      -0.280340       1.676285       0.288266      -0.997313   \n",
      "1006       0.875318       1.114214      -0.613728       0.474163   \n",
      "1007      -0.261334       1.289066      -2.149494       0.720941   \n",
      "1008       0.701940       0.707417       0.516834      -0.112388   \n",
      "\n",
      "      feat_esm1b_89  feat_esm1b_125  ...  feat_esm1b_1208  feat_esm1b_1216  \\\n",
      "0          1.217534        0.138518  ...        -0.673357        -1.416327   \n",
      "1          0.145763       -0.073682  ...        -0.885079        -0.611905   \n",
      "2          0.601087        0.648192  ...        -0.763415         0.466507   \n",
      "3         -0.795914       -0.692428  ...         0.615477        -0.661766   \n",
      "4          0.282560        0.301663  ...         0.278159        -0.171671   \n",
      "...             ...             ...  ...              ...              ...   \n",
      "1004      -0.374645        1.063852  ...         0.240876         0.015928   \n",
      "1005      -0.196167        0.944529  ...        -0.950143        -1.091482   \n",
      "1006       0.577033       -0.083737  ...         0.274717         0.765290   \n",
      "1007      -0.335808        0.675640  ...         1.005635        -1.162581   \n",
      "1008       0.111655        0.407566  ...        -0.212193         0.238493   \n",
      "\n",
      "      feat_esm1b_1223  feat_esm1b_1231  feat_esm1b_1233  feat_esm1b_1237  \\\n",
      "0            0.860869        -0.518130         0.697049        -0.031926   \n",
      "1            1.835822        -1.885295         1.908645         2.279289   \n",
      "2            0.516378        -0.094872         0.295894         0.386173   \n",
      "3            0.893480        -1.254536        -0.071535         1.474643   \n",
      "4            1.908259         0.034151        -0.516294         0.230244   \n",
      "...               ...              ...              ...              ...   \n",
      "1004         0.586818        -0.648641        -0.057151         0.217596   \n",
      "1005        -0.065917         0.864101         0.506150         1.058646   \n",
      "1006        -0.143276         0.301170         0.237022         0.002695   \n",
      "1007        -1.722244        -0.736167        -0.983018        -0.340027   \n",
      "1008         0.445586         0.110617        -0.764445         0.270881   \n",
      "\n",
      "      feat_esm1b_1239  feat_esm1b_1240  feat_esm1b_1274  Class  \n",
      "0            0.266899        -0.962571        -0.061837      1  \n",
      "1           -0.751778        -0.302810        -1.149024      1  \n",
      "2           -0.383013        -0.809577        -1.031388     -1  \n",
      "3           -0.539213         0.289913         1.223725      1  \n",
      "4           -0.805542        -0.275951        -0.219079      1  \n",
      "...               ...              ...              ...    ...  \n",
      "1004        -0.047475        -1.320653        -0.134324      1  \n",
      "1005        -0.034335        -0.650890        -0.819523     -1  \n",
      "1006         0.674271         0.093678        -0.261049      1  \n",
      "1007        -1.789441         0.241471        -0.699585      1  \n",
      "1008        -1.386385        -0.883308        -0.441517     -1  \n",
      "\n",
      "[1009 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "lentivirus.dropna(inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(lentivirus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eefc37e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 504\n",
      "Testing data size: 252\n",
      "Hold-out data size: 253\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training and remaining data (50%)\n",
    "lenti_train, remaining_data = train_test_split(lentivirus, test_size=0.5, random_state=42)\n",
    "\n",
    "# Splitting the remaining data into testing and hold-out (50% of remaining data each)\n",
    "lenti_test, holdout_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Printing the sizes of each split\n",
    "print(\"Training data size:\", len(lenti_train))\n",
    "print(\"Testing data size:\", len(lenti_test))\n",
    "print(\"Hold-out data size:\", len(holdout_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6980c608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_cluster</th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>-0.824814</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.035782</td>\n",
       "      <td>0.979575</td>\n",
       "      <td>-0.766056</td>\n",
       "      <td>0.444185</td>\n",
       "      <td>1.394861</td>\n",
       "      <td>0.612468</td>\n",
       "      <td>-1.114174</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159696</td>\n",
       "      <td>0.183484</td>\n",
       "      <td>-0.860851</td>\n",
       "      <td>-0.056895</td>\n",
       "      <td>-0.577265</td>\n",
       "      <td>0.586591</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>-0.795856</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>0.443079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>-0.824814</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.528182</td>\n",
       "      <td>-0.165631</td>\n",
       "      <td>-1.222852</td>\n",
       "      <td>0.070939</td>\n",
       "      <td>1.653314</td>\n",
       "      <td>0.594089</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>0.164048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176838</td>\n",
       "      <td>-1.512071</td>\n",
       "      <td>1.032958</td>\n",
       "      <td>-2.108587</td>\n",
       "      <td>1.908715</td>\n",
       "      <td>1.978000</td>\n",
       "      <td>0.917692</td>\n",
       "      <td>-0.128516</td>\n",
       "      <td>-1.610395</td>\n",
       "      <td>-2.122749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>-0.828945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713430</td>\n",
       "      <td>-0.293336</td>\n",
       "      <td>-0.886169</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>0.739857</td>\n",
       "      <td>0.866343</td>\n",
       "      <td>0.914079</td>\n",
       "      <td>-0.210403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571137</td>\n",
       "      <td>0.632350</td>\n",
       "      <td>1.311923</td>\n",
       "      <td>0.210717</td>\n",
       "      <td>-1.107030</td>\n",
       "      <td>-0.748033</td>\n",
       "      <td>-0.465388</td>\n",
       "      <td>0.346508</td>\n",
       "      <td>-0.731403</td>\n",
       "      <td>-0.977556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>0.067480</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.793059</td>\n",
       "      <td>1.376617</td>\n",
       "      <td>-2.057538</td>\n",
       "      <td>1.752255</td>\n",
       "      <td>1.681570</td>\n",
       "      <td>-0.512685</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>-0.381660</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414444</td>\n",
       "      <td>-0.055830</td>\n",
       "      <td>0.927312</td>\n",
       "      <td>-0.712120</td>\n",
       "      <td>1.435082</td>\n",
       "      <td>-0.996910</td>\n",
       "      <td>0.117121</td>\n",
       "      <td>-0.560064</td>\n",
       "      <td>-0.591450</td>\n",
       "      <td>0.415383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>-0.824814</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.443476</td>\n",
       "      <td>-1.256478</td>\n",
       "      <td>0.717991</td>\n",
       "      <td>-1.459524</td>\n",
       "      <td>-0.578907</td>\n",
       "      <td>-0.175691</td>\n",
       "      <td>-0.595183</td>\n",
       "      <td>-0.141326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588146</td>\n",
       "      <td>-0.496221</td>\n",
       "      <td>0.551593</td>\n",
       "      <td>-0.538332</td>\n",
       "      <td>0.657561</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.034470</td>\n",
       "      <td>-1.340179</td>\n",
       "      <td>-0.655143</td>\n",
       "      <td>0.068784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>-0.742194</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.959265</td>\n",
       "      <td>0.741581</td>\n",
       "      <td>0.837996</td>\n",
       "      <td>-0.191848</td>\n",
       "      <td>-0.469900</td>\n",
       "      <td>0.583160</td>\n",
       "      <td>1.854512</td>\n",
       "      <td>-1.134049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518591</td>\n",
       "      <td>-1.457706</td>\n",
       "      <td>0.963332</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>0.221848</td>\n",
       "      <td>-0.762170</td>\n",
       "      <td>1.580194</td>\n",
       "      <td>0.620111</td>\n",
       "      <td>0.618390</td>\n",
       "      <td>0.037759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>-0.754587</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.081655</td>\n",
       "      <td>0.627396</td>\n",
       "      <td>0.559133</td>\n",
       "      <td>-0.918488</td>\n",
       "      <td>-1.108461</td>\n",
       "      <td>-0.577984</td>\n",
       "      <td>0.346922</td>\n",
       "      <td>0.178223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096852</td>\n",
       "      <td>-1.280123</td>\n",
       "      <td>1.638585</td>\n",
       "      <td>0.127432</td>\n",
       "      <td>0.034772</td>\n",
       "      <td>-0.677343</td>\n",
       "      <td>-0.987537</td>\n",
       "      <td>-0.098453</td>\n",
       "      <td>1.470712</td>\n",
       "      <td>1.368686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>-0.630657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234470</td>\n",
       "      <td>2.198867</td>\n",
       "      <td>-1.087524</td>\n",
       "      <td>-0.991205</td>\n",
       "      <td>-0.414148</td>\n",
       "      <td>-1.414801</td>\n",
       "      <td>0.240022</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>...</td>\n",
       "      <td>3.539059</td>\n",
       "      <td>-2.401729</td>\n",
       "      <td>0.633103</td>\n",
       "      <td>-0.057441</td>\n",
       "      <td>0.567661</td>\n",
       "      <td>-0.863206</td>\n",
       "      <td>-1.531303</td>\n",
       "      <td>-0.784238</td>\n",
       "      <td>0.606125</td>\n",
       "      <td>0.883982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>-0.647181</td>\n",
       "      <td>1</td>\n",
       "      <td>1.398936</td>\n",
       "      <td>1.871653</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>-1.943764</td>\n",
       "      <td>0.321617</td>\n",
       "      <td>0.370039</td>\n",
       "      <td>-0.254844</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319585</td>\n",
       "      <td>-0.579820</td>\n",
       "      <td>0.651883</td>\n",
       "      <td>0.194037</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.655054</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>1.028218</td>\n",
       "      <td>-0.230643</td>\n",
       "      <td>-1.366489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>-0.684360</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.585094</td>\n",
       "      <td>0.050078</td>\n",
       "      <td>0.486875</td>\n",
       "      <td>-0.049218</td>\n",
       "      <td>0.649688</td>\n",
       "      <td>0.134988</td>\n",
       "      <td>0.237264</td>\n",
       "      <td>-0.326935</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.701238</td>\n",
       "      <td>1.221676</td>\n",
       "      <td>0.525293</td>\n",
       "      <td>0.220452</td>\n",
       "      <td>-0.682368</td>\n",
       "      <td>-0.024442</td>\n",
       "      <td>0.892712</td>\n",
       "      <td>0.119388</td>\n",
       "      <td>0.771982</td>\n",
       "      <td>0.944944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3708 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Info_cluster  Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  \\\n",
       "4732     -0.824814     -1     -0.035782      0.979575     -0.766056   \n",
       "1077     -0.824814      1     -1.528182     -0.165631     -1.222852   \n",
       "3292     -0.828945      1      0.713430     -0.293336     -0.886169   \n",
       "2618      0.067480     -1      0.793059      1.376617     -2.057538   \n",
       "4245     -0.824814     -1     -0.443476     -1.256478      0.717991   \n",
       "...            ...    ...           ...           ...           ...   \n",
       "4481     -0.742194      1     -0.959265      0.741581      0.837996   \n",
       "468      -0.754587     -1     -0.081655      0.627396      0.559133   \n",
       "3126     -0.630657      1      0.234470      2.198867     -1.087524   \n",
       "3819     -0.647181      1      1.398936      1.871653      0.017419   \n",
       "866      -0.684360      1     -0.585094      0.050078      0.486875   \n",
       "\n",
       "      feat_esm1b_3  feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  \\\n",
       "4732      0.444185      1.394861      0.612468     -1.114174      0.080074   \n",
       "1077      0.070939      1.653314      0.594089      0.065991      0.164048   \n",
       "3292     -0.004658      0.739857      0.866343      0.914079     -0.210403   \n",
       "2618      1.752255      1.681570     -0.512685      0.806652     -0.381660   \n",
       "4245     -1.459524     -0.578907     -0.175691     -0.595183     -0.141326   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4481     -0.191848     -0.469900      0.583160      1.854512     -1.134049   \n",
       "468      -0.918488     -1.108461     -0.577984      0.346922      0.178223   \n",
       "3126     -0.991205     -0.414148     -1.414801      0.240022     -0.318511   \n",
       "3819     -1.943764      0.321617      0.370039     -0.254844      0.001111   \n",
       "866      -0.049218      0.649688      0.134988      0.237264     -0.326935   \n",
       "\n",
       "      ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "4732  ...         0.159696         0.183484        -0.860851        -0.056895   \n",
       "1077  ...        -0.176838        -1.512071         1.032958        -2.108587   \n",
       "3292  ...        -0.571137         0.632350         1.311923         0.210717   \n",
       "2618  ...         1.414444        -0.055830         0.927312        -0.712120   \n",
       "4245  ...         0.588146        -0.496221         0.551593        -0.538332   \n",
       "...   ...              ...              ...              ...              ...   \n",
       "4481  ...        -0.518591        -1.457706         0.963332         0.025562   \n",
       "468   ...         1.096852        -1.280123         1.638585         0.127432   \n",
       "3126  ...         3.539059        -2.401729         0.633103        -0.057441   \n",
       "3819  ...         0.319585        -0.579820         0.651883         0.194037   \n",
       "866   ...        -1.701238         1.221676         0.525293         0.220452   \n",
       "\n",
       "      feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "4732        -0.577265         0.586591         0.007725        -0.795856   \n",
       "1077         1.908715         1.978000         0.917692        -0.128516   \n",
       "3292        -1.107030        -0.748033        -0.465388         0.346508   \n",
       "2618         1.435082        -0.996910         0.117121        -0.560064   \n",
       "4245         0.657561         0.993569         0.034470        -1.340179   \n",
       "...               ...              ...              ...              ...   \n",
       "4481         0.221848        -0.762170         1.580194         0.620111   \n",
       "468          0.034772        -0.677343        -0.987537        -0.098453   \n",
       "3126         0.567661        -0.863206        -1.531303        -0.784238   \n",
       "3819         0.070741         0.655054         0.323026         1.028218   \n",
       "866         -0.682368        -0.024442         0.892712         0.119388   \n",
       "\n",
       "      feat_esm1b_1278  feat_esm1b_1279  \n",
       "4732         0.152716         0.443079  \n",
       "1077        -1.610395        -2.122749  \n",
       "3292        -0.731403        -0.977556  \n",
       "2618        -0.591450         0.415383  \n",
       "4245        -0.655143         0.068784  \n",
       "...               ...              ...  \n",
       "4481         0.618390         0.037759  \n",
       "468          1.470712         1.368686  \n",
       "3126         0.606125         0.883982  \n",
       "3819        -0.230643        -1.366489  \n",
       "866          0.771982         0.944944  \n",
       "\n",
       "[3708 rows x 1282 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea85fa",
   "metadata": {},
   "source": [
    "Concatenate lentivirus training dataset and \"all viruses\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64c0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train_data and lenti_train DataFrames\n",
    "final_train = pd.concat([train_data[selected_features], lenti_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2003c6",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a5b648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "class_counts = final_train[\"Class\"].value_counts()\n",
    "\n",
    "# Set seaborn aesthetic parameters\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the class balance using a bar plot\n",
    "ax = class_counts.plot(kind='bar', figsize=(8, 6), color='cornflowerblue')\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title('Class Balance', fontsize=16)\n",
    "\n",
    "# Annotate the exact number on each bar\n",
    "for i, v in enumerate(class_counts):\n",
    "    ax.text(i, v + 0.2, str(v), color='black', ha='center', fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e761743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MCC: 0.6562955635915949\n",
      "Logistic Regression MCC: 0.31051210826017955\n",
      "Support Vector Machine MCC: 0.8072529588964096\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Adjust class weights as needed\n",
    "class_weights = {1: 50, -1: 50}\n",
    "\n",
    "X_train =final_train.drop(columns=\"Class\")\n",
    "y_train = final_train[\"Class\"]\n",
    "X_test = lenti_test.drop(columns=\"Class\")\n",
    "y_test = lenti_test[\"Class\"]\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(class_weight=class_weights, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "lr_model = LogisticRegression(class_weight=class_weights, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the Support Vector Machine model\n",
    "svm_model = SVC(class_weight=class_weights, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate the MCC value for each model\n",
    "rf_mcc = matthews_corrcoef(y_test, rf_predictions)\n",
    "lr_mcc = matthews_corrcoef(y_test, lr_predictions)\n",
    "svm_mcc = matthews_corrcoef(y_test, svm_predictions)\n",
    "\n",
    "# Print the MCC values\n",
    "print(\"Random Forest MCC:\", rf_mcc)\n",
    "print(\"Logistic Regression MCC:\", lr_mcc)\n",
    "print(\"Support Vector Machine MCC:\", svm_mcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90ab85",
   "metadata": {},
   "source": [
    "Save holdout dataset and combine training and testing set for lentivirus for future implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfafbeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lentivirus_holdout = holdout_data.to_csv(\"lentivirus_holdout.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d163e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lenti_test and lenti_train\n",
    "combined_dataset = pd.concat([lenti_test, lenti_train])\n",
    "\n",
    "# Save the combined dataset to a CSV file\n",
    "combined_dataset.to_csv(\"lentivirus_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f4eb7",
   "metadata": {},
   "source": [
    "# Data Mining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85db1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def run_pipeline(df, lentivirus_data, class_weights):\n",
    "    # Drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Drop columns starting with \"Info_\" except \"Info_cluster\"\n",
    "    columns_to_drop = df.filter(regex='^Info_(?!cluster)').columns\n",
    "    df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    selected_features = ['Info_cluster','feat_esm1b_15','feat_esm1b_38','feat_esm1b_46','feat_esm1b_69','feat_esm1b_70',\n",
    "         'feat_esm1b_76',\n",
    "         'feat_esm1b_87',\n",
    "         'feat_esm1b_89',\n",
    "         'feat_esm1b_125',\n",
    "         'feat_esm1b_128',\n",
    "         'feat_esm1b_141',\n",
    "         'feat_esm1b_162',\n",
    "         'feat_esm1b_179',\n",
    "         'feat_esm1b_188',\n",
    "         'feat_esm1b_197',\n",
    "         'feat_esm1b_213',\n",
    "         'feat_esm1b_217',\n",
    "         'feat_esm1b_224',\n",
    "         'feat_esm1b_252',\n",
    "         'feat_esm1b_254',\n",
    "         'feat_esm1b_255',\n",
    "         'feat_esm1b_265',\n",
    "         'feat_esm1b_267',\n",
    "         'feat_esm1b_279',\n",
    "         'feat_esm1b_290',\n",
    "         'feat_esm1b_302',\n",
    "         'feat_esm1b_303',\n",
    "         'feat_esm1b_304',\n",
    "         'feat_esm1b_308',\n",
    "         'feat_esm1b_313',\n",
    "         'feat_esm1b_324',\n",
    "         'feat_esm1b_330',\n",
    "         'feat_esm1b_331',\n",
    "         'feat_esm1b_343',\n",
    "         'feat_esm1b_344',\n",
    "         'feat_esm1b_358',\n",
    "         'feat_esm1b_367',\n",
    "         'feat_esm1b_392',\n",
    "         'feat_esm1b_397',\n",
    "         'feat_esm1b_413',\n",
    "         'feat_esm1b_423',\n",
    "         'feat_esm1b_434',\n",
    "         'feat_esm1b_447',\n",
    "         'feat_esm1b_450',\n",
    "         'feat_esm1b_455',\n",
    "         'feat_esm1b_457',\n",
    "         'feat_esm1b_459',\n",
    "         'feat_esm1b_472',\n",
    "         'feat_esm1b_474',\n",
    "         'feat_esm1b_476',\n",
    "         'feat_esm1b_484',\n",
    "         'feat_esm1b_487',\n",
    "         'feat_esm1b_494',\n",
    "         'feat_esm1b_500',\n",
    "         'feat_esm1b_509',\n",
    "         'feat_esm1b_526',\n",
    "         'feat_esm1b_535',\n",
    "         'feat_esm1b_541',\n",
    "         'feat_esm1b_564',\n",
    "         'feat_esm1b_570',\n",
    "         'feat_esm1b_600',\n",
    "         'feat_esm1b_621',\n",
    "         'feat_esm1b_628',\n",
    "         'feat_esm1b_639',\n",
    "         'feat_esm1b_643',\n",
    "         'feat_esm1b_646',\n",
    "         'feat_esm1b_659',\n",
    "         'feat_esm1b_665',\n",
    "         'feat_esm1b_668',\n",
    "         'feat_esm1b_669',\n",
    "         'feat_esm1b_670',\n",
    "         'feat_esm1b_671',\n",
    "         'feat_esm1b_679',\n",
    "         'feat_esm1b_684',\n",
    "         'feat_esm1b_699',\n",
    "         'feat_esm1b_711',\n",
    "         'feat_esm1b_725',\n",
    "         'feat_esm1b_728',\n",
    "         'feat_esm1b_733',\n",
    "         'feat_esm1b_741',\n",
    "         'feat_esm1b_757',\n",
    "         'feat_esm1b_771',\n",
    "         'feat_esm1b_777',\n",
    "         'feat_esm1b_785',\n",
    "         'feat_esm1b_789',\n",
    "         'feat_esm1b_795',\n",
    "         'feat_esm1b_801',\n",
    "         'feat_esm1b_805',\n",
    "         'feat_esm1b_810',\n",
    "         'feat_esm1b_847',\n",
    "         'feat_esm1b_854',\n",
    "         'feat_esm1b_874',\n",
    "         'feat_esm1b_877',\n",
    "         'feat_esm1b_882',\n",
    "         'feat_esm1b_884',\n",
    "         'feat_esm1b_898',\n",
    "         'feat_esm1b_904',\n",
    "         'feat_esm1b_909',\n",
    "         'feat_esm1b_927',\n",
    "         'feat_esm1b_928',\n",
    "         'feat_esm1b_929',\n",
    "         'feat_esm1b_933',\n",
    "         'feat_esm1b_936',\n",
    "         'feat_esm1b_942',\n",
    "         'feat_esm1b_960',\n",
    "         'feat_esm1b_966',\n",
    "         'feat_esm1b_1015',\n",
    "         'feat_esm1b_1043',\n",
    "         'feat_esm1b_1050',\n",
    "         'feat_esm1b_1056',\n",
    "         'feat_esm1b_1103',\n",
    "         'feat_esm1b_1109',\n",
    "         'feat_esm1b_1110',\n",
    "         'feat_esm1b_1125',\n",
    "         'feat_esm1b_1132',\n",
    "         'feat_esm1b_1148',\n",
    "         'feat_esm1b_1153',\n",
    "         'feat_esm1b_1156',\n",
    "         'feat_esm1b_1159',\n",
    "         'feat_esm1b_1166',\n",
    "         'feat_esm1b_1167',\n",
    "         'feat_esm1b_1180',\n",
    "         'feat_esm1b_1183',\n",
    "         'feat_esm1b_1186',\n",
    "         'feat_esm1b_1208',\n",
    "         'feat_esm1b_1216',\n",
    "         'feat_esm1b_1223',\n",
    "         'feat_esm1b_1231',\n",
    "         'feat_esm1b_1233',\n",
    "         'feat_esm1b_1237',\n",
    "         'feat_esm1b_1239',\n",
    "         'feat_esm1b_1240',\n",
    "         'feat_esm1b_1274',\n",
    "         'Class']\n",
    "\n",
    "    df = df[selected_features]\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    mask = df.columns != \"Class\"\n",
    "    df.loc[:, mask] = scaler.fit_transform(df.loc[:, mask])\n",
    "\n",
    "    lentivirus = lentivirus_data[selected_features]\n",
    "    mask = lentivirus.columns != \"Class\"\n",
    "    lentivirus.loc[:, mask] = scaler.transform(lentivirus.loc[:, mask])\n",
    "\n",
    " \n",
    "    lentivirus_train, lentivirus_test = train_test_split(lentivirus, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Concatenate lentivirus train data with the training data\n",
    "    final_train = pd.concat([df, lentivirus_train], ignore_index=True)\n",
    "\n",
    "    # Define the target variables for training and testing\n",
    "    y_train = final_train[\"Class\"]\n",
    "    y_test = lentivirus_test[\"Class\"]\n",
    "\n",
    "    # Remove the \"Class\" column from the datasets\n",
    "    X_train = final_train.drop(columns=\"Class\")\n",
    "    X_test = lentivirus_test.drop(columns=\"Class\")\n",
    "\n",
    "    # Train the models\n",
    "    rf_model = RandomForestClassifier(class_weight=class_weights, random_state=42)\n",
    "    lr_model = LogisticRegression(class_weight=class_weights, random_state=42)\n",
    "    svm_model = SVC(class_weight=class_weights, random_state=42)\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    lr_predictions = lr_model.predict(X_test)\n",
    "    svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "    # Calculate the MCC value for each model\n",
    "    rf_mcc = matthews_corrcoef(y_test, rf_predictions)\n",
    "    lr_mcc = matthews_corrcoef(y_test, lr_predictions)\n",
    "    svm_mcc = matthews_corrcoef(y_test, svm_predictions)\n",
    "\n",
    "    # Return the MCC values\n",
    "    return rf_mcc, lr_mcc, svm_mcc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ab52b",
   "metadata": {},
   "source": [
    "## Testing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebe1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_viruses_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cba0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MCC: 0.7104913482599073\n",
      "Logistic Regression MCC: 0.517376733509516\n",
      "Support Vector Machine MCC: 0.4488819027605528\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "df = resample(\n",
    "    df,\n",
    "    replace=False,\n",
    "    n_samples=8000,  # Adjust the desired size accordingly\n",
    "    random_state=42\n",
    ").reset_index(drop=True)\n",
    "lentivirus_data = pd.read_csv(\"lentivirus_data.csv\")\n",
    "\n",
    "class_weights = {1: 50, -1: 50}\n",
    "\n",
    "rf_mcc, lr_mcc, svm_mcc = run_pipeline(df, lentivirus_data, class_weights)\n",
    "\n",
    "print(\"Random Forest MCC:\", rf_mcc)\n",
    "print(\"Logistic Regression MCC:\", lr_mcc)\n",
    "print(\"Support Vector Machine MCC:\", svm_mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0636f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
